{
    "metadata": {
      "author":"Tev'n Powers",
      "created":"\"2020-02-05T70:00\"",
      "saved":"\"2020-02-06T00:50\"",
      "id": "35093533-1fea-4913-949d-13d6c2f3ec9b"
    },
    "loaders": [
      {
        "id": "05eea941-5ae7-4acf-884a-dfb863755b79",
        "name": "CsvLoader",
        "display_name": "CSV Loader",
        "config": [
            {
                "name": "Delimiter",
                "value": ",",
                "type": "string",
                "description": "The token that separates columns in dataset."
            }
        ]

      }
    ],
    "data": [
      {
        "id": "5eacbf07-d9b8-4d02-b674-8badb7703e2a",
        "name": "Fanfiction Stories",
        "description": "This is a set of 1M html tagged fanfiction stories written from 2012-2015.",
        "languages": ["English"],
        "path": "../data/story_content.csv",
        "config": {
          "loader_id": "05eea941-5ae7-4acf-884a-dfb863755b79"
        }
      },
      {
        "id": "cf9c5dac-0f8d-4a57-a176-9130068f48f1",
        "name": "Fanfiction Stories (Clean)",
        "description": "This is a set of 1M fanfiction stories written from 2012-2015.",
        "languages": ["English"],
        "path": "../data/story_content_cleaned.csv",
        "config": {
          "loader_id": "05eea941-5ae7-4acf-884a-dfb863755b79"
        }
      },
      {
        "id": "857292df-7cb7-4d17-a95a-bd570be378be",
        "name": "Fanfiction Fandoms",
        "description": "This is a set of 1M fanfiction stories written from 2012-2015 grouped by fandom.",
        "languages": ["English"],
        "path": "../data/fandoms.csv",
        "config": {
          "loader_id": "05eea941-5ae7-4acf-884a-dfb863755b79"
        }
      }
    ],
    "annotators": [
      {
        "id": "4991a5d6-b64c-4dd6-bedc-87b354b575bf",
        "name": "HtmlParser",
        "path": "html_parser.py",
        "description": "Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping. It is available for Python 2.7 and Python 3. ",
        "config": {
          "name": "Html Parser",
          "keys": [
            {
              "name" : "Input",
              "value": "story_content_content",
              "type": "string",
              "description": "This is the key for your HTML text that should be processed by the annotator."
            }
          ],
          "annotations": [
            {
              "name" : "Output",
              "value": "text",
              "type": "string",
              "description": "After processing, this with be the key to access the cleaned text."
            }
          ]
        }
      },
      {
        "id": "630a1ed2-fa02-441a-bf89-ee708c7529a0",
        "name": "Accumulator",
        "path": "accumulator.py",
        "description": "This accumulates...",
        "config": {
          "name": "Accumulator",
          "keys": [
                {
                    "name": "Category ID",
                    "value": "story_fandom_id",
                    "type": "string",
                    "description": "first key description"
                },
                {
                    "name": "Input Text",
                    "value": "filtered_text",
                    "description": "second key description"
                }
            ],
          "annotations": [
              {
                "name": "Category ID",
                "value": "id",
                "type": "string",
                "description": "The ID that text collections are grouped by."
              },
              {
                "name": "Category Text",
                "value": "text",
                "type": "string",
                "description": "Text from all data instances in this category."
              }
            ]
        }
      },
      {
        "id": "e897400d-36e6-454c-9bd4-8bf5b9195a0b",
        "name": "PosTagger",
        "path": "pos_tagger.py",
        "description": "A part-of-speech tagger, or POS-tagger, processes a sequence of words, and attaches a part of speech tag to each word. Parts of speech tagging can be important for syntactic and semantic analysis.",
        "config": {
          "name": "Tagger",
          "keys": [
                {
                    "name": "Input Text",
                    "value": "text",
                    "type": "string",
                    "description": "Text to part of speech tag."
                }
            ],
          "annotations": [
            {
                "name": "POS Tags",
                "value": "tagged_tokens",
                "type": "string",
                "description": "Part of speech tagged tokens."
            },
            {
                "name": "Output Text",
                "value": "filtered_text",
                "type": "string",
                "description": "Raw text after applying filters."
            }
            ],
          "filters": ["NNP", "NNPS"]
        }
      }
    ],
    "actions": [
      {
        "id": "caeadf1d-40b5-4ba1-8817-5d890ad5c3bc",
        "name": "WordCloud",
        "description": "Produce word clouds...",
        "path": "word_cloud.py",
        "config": {
          "name": "Word Cloud",
          "keys": [
                {
                    "name": "Category ID",
                    "value": "id",
                    "type": "string",
                    "description": "Optional ID for grouping word cloud input."
                },
                {
                    "name": "Input Text",
                    "value": "text",
                    "type": "string",
                    "description": "Raw text to count."
                }
            ]
        }
      }
    ],
    "pipelines": [
      {
        "id": "b2e347ed-7a77-46e1-a024-0f8e43ec3a6c",
        "name": "FanFict",
        "description": "This pipeline processes text from the UW HCDE Fan Fiction story dataset to identify the most popular proper nouns in each fandom present in the dataset. The data in this table is HTML formatted. The pipeline begins by using Python's Beautiful Soup module to parse the HTML in order to produce cleaned text. Afterwards, we use the Python Natural Language Toolkit's (NLTK) to tag each word in the cleaned text with its part of speech and filter to just proper noun tagged tokens. Now we can merge all of the data examples by their fandoms. Lastly, we use the Word Cloud module to produce a visualization of the most common proper nouns.",
        "components": [
          "4991a5d6-b64c-4dd6-bedc-87b354b575bf",
          "e897400d-36e6-454c-9bd4-8bf5b9195a0b",
          "630a1ed2-fa02-441a-bf89-ee708c7529a0",
          "caeadf1d-40b5-4ba1-8817-5d890ad5c3bc"
        ]
      }
    ]
  }